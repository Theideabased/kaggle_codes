{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Import Packages","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport jpx_tokyo_market_prediction\nfrom lightgbm import LGBMRegressor\nimport optuna.integration.lightgbm as lgb\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport datetime\nimport warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"execution":{"iopub.status.busy":"2022-07-05T03:54:09.484526Z","iopub.execute_input":"2022-07-05T03:54:09.484897Z","iopub.status.idle":"2022-07-05T03:54:09.491096Z","shell.execute_reply.started":"2022-07-05T03:54:09.484869Z","shell.execute_reply":"2022-07-05T03:54:09.489956Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"（Load Data）","metadata":{}},{"cell_type":"code","source":"prices = pd.read_csv(\"../input/jpx-tokyo-stock-exchange-prediction/supplemental_files/stock_prices.csv\", parse_dates=[\"Date\"])","metadata":{"execution":{"iopub.status.busy":"2022-07-05T03:54:11.024618Z","iopub.execute_input":"2022-07-05T03:54:11.025003Z","iopub.status.idle":"2022-07-05T03:54:11.644224Z","shell.execute_reply.started":"2022-07-05T03:54:11.024973Z","shell.execute_reply":"2022-07-05T03:54:11.642993Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# EDA","metadata":{}},{"cell_type":"code","source":"prices","metadata":{"execution":{"iopub.status.busy":"2022-07-05T03:54:12.764630Z","iopub.execute_input":"2022-07-05T03:54:12.765024Z","iopub.status.idle":"2022-07-05T03:54:12.799170Z","shell.execute_reply.started":"2022-07-05T03:54:12.764990Z","shell.execute_reply":"2022-07-05T03:54:12.798097Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"column information<br>\n(1) RowId: ID Date_SecuritiesCode, Unique ID of price records <br>\n(2) Date: Trade date <br>\n(3) SecuritiesCode: Local securities code, 2000 <br>\n(4) Open: First traded price on a day<br>\n(5) High: Highest traded price on a day <br>\n(6) Low : Lowest traded price on a day <br>\n(7) Close: Last traded price on a day <br>\n(8) Volume: Number of traded stocks on a day <br>\n(9) AdjustmentFactor：Change in stock price due to a split/reverse split. Correction from the closing price to the beginning of the next day.）<br>\n(10) ExpectedDividend: Projected dividend amount <br>\n(11) SupervisionFlag: Flag for supervised and delisted stocks. High risk of delisting. <br>\n(12) Target: Target variable; rate of return derived from the difference between one and two days later <br>","metadata":{}},{"cell_type":"markdown","source":"## Check missing values","metadata":{}},{"cell_type":"code","source":"#Check the number of missing values per column\nprices.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2022-07-05T03:54:14.861299Z","iopub.execute_input":"2022-07-05T03:54:14.861732Z","iopub.status.idle":"2022-07-05T03:54:14.908989Z","shell.execute_reply.started":"2022-07-05T03:54:14.861701Z","shell.execute_reply":"2022-07-05T03:54:14.907859Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### ","metadata":{}},{"cell_type":"code","source":"#\"Open\", \"High\", \"Low\", \"Close\"（（Check about missing values of \"Open\", \"High\", \"Low\", \"Close\"）\nprint((prices[\"Open\"].isnull() == (prices[\"Volume\"]==0)).all())\nprint((prices[\"High\"].isnull() == (prices[\"Volume\"]==0)).all())\nprint((prices[\"Low\"].isnull() == (prices[\"Volume\"]==0)).all())\nprint((prices[\"Close\"].isnull() == (prices[\"Volume\"]==0)).all())\n#\"Volume\"（\"Volume\" represents the total amount traded on that day.）\n#（So, \"Volume = 0\" means that there was no trading on that day, and the opening, high, low, and closing prices are null.）","metadata":{"execution":{"iopub.status.busy":"2022-07-05T03:54:16.232233Z","iopub.execute_input":"2022-07-05T03:54:16.233200Z","iopub.status.idle":"2022-07-05T03:54:16.253116Z","shell.execute_reply.started":"2022-07-05T03:54:16.233146Z","shell.execute_reply":"2022-07-05T03:54:16.251759Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#\"ExpectedDividend\"（Check about missing values of \"\"ExpectedDividend\"）\nprices[(~prices[\"ExpectedDividend\"].isnull())][\"Date\"].value_counts()\n#（Value exists only on certain days. The value may be filled at the time of closing.）","metadata":{"execution":{"iopub.status.busy":"2022-07-05T03:54:17.392841Z","iopub.execute_input":"2022-07-05T03:54:17.393503Z","iopub.status.idle":"2022-07-05T03:54:17.404612Z","shell.execute_reply.started":"2022-07-05T03:54:17.393457Z","shell.execute_reply":"2022-07-05T03:54:17.403669Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#（Check for missing dates）\nprices[\"SecuritiesCode\"].value_counts().sort_values()\n#（1413 misses 21days, 8806 misses 20days, 4699 misses 1day）","metadata":{"execution":{"iopub.status.busy":"2022-07-05T03:54:18.144519Z","iopub.execute_input":"2022-07-05T03:54:18.145145Z","iopub.status.idle":"2022-07-05T03:54:18.156343Z","shell.execute_reply.started":"2022-07-05T03:54:18.145108Z","shell.execute_reply":"2022-07-05T03:54:18.155251Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#（Check for missing dates）\npd.pivot(prices, index=\"Date\", columns=\"SecuritiesCode\", values=\"Volume\")[[1413, 8806, 4699, 1375]].tail(30)\n#（1413 misses 2022-04-25～2022-05-27）\n#（8806 misses 2022-04-26～2022-05-27）\n#（4699 misses 2022-05-27）","metadata":{"execution":{"iopub.status.busy":"2022-07-05T03:54:18.812802Z","iopub.execute_input":"2022-07-05T03:54:18.813502Z","iopub.status.idle":"2022-07-05T03:54:18.889855Z","shell.execute_reply.started":"2022-07-05T03:54:18.813454Z","shell.execute_reply":"2022-07-05T03:54:18.888655Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Feature generation and selection）","metadata":{}},{"cell_type":"code","source":"def MA(series, window=25):\n    return series.rolling(window, min_periods=1).mean()\n\ndef DMA(series, window=25):\n    return series/MA(series, window) - 1\n\ndef divergence(series, window=25):\n    std = series.rolling(window,min_periods=1).std()\n    mean = series.rolling(window,min_periods=1).mean()\n    return (series-mean) / std    \n\ndef rsi(series, n=14):\n    return (series - series.shift(1)).rolling(n).apply(lambda s:s[s>0].sum()/abs(s).sum())\n\ndef stochastic(series, k=14, n=3, m=3):\n    _min = series.rolling(k).min()\n    _max = series.rolling(k).max()\n    _k = (series - _min)/(_max - _min)\n    _d1 = _k.rolling(n).mean()\n    _d2 = _d1.rolling(m).mean()\n    return pd.DataFrame({\n                    \"%K\":_k,\n                    \"FAST-%D\":_d1,\n                    \"SLOW-%D\":_d2,\n                    },index=series.index)\n    # return _k, _d1, _d2\n\ndef psy(series, n=14):\n    return (series - series.shift(1)).rolling(n).apply(lambda s:(s>=0).mean())\n\ndef ICH(series):\n    conv = series.rolling(9).apply(lambda s:(s.max()+s.min())/2)\n    base = series.rolling(26).apply(lambda s:(s.max()+s.min())/2)\n    pre1 = ((conv + base)/2).shift(25)\n    pre2 = d.Close_adj.rolling(52).apply(lambda s:(s.max()+s.min())/2).shift(25)\n    lagg = d.Close_adj.shift(25)\n    return conv, base, pre1, pre2, lagg\n\ndef roc(series, window=14):\n    return series/series.shift(window) - 1\n\nclass FeatureBase():\n    def create_feature(self, d):\n        assert False, \"NotImplemented\"\n        \nclass MAFeature(FeatureBase):\n    def create_feature(self, d):\n        return self._create_feature(d[\"Close_adj\"])\n\n    def _create_feature(self, series, window1=5, window2=25):\n        ma1 = MA(series, window1).rename(\"MA1\")\n        ma2 = MA(series, window2).rename(\"MA2\")\n        diff = ma1 - ma2\n        cross = pd.Series(\n                        np.where((diff>0) & (diff<0).shift().fillna(False), 1,\n                            np.where((diff<0) & (diff>0).shift().fillna(False), -1, 0\n                                )\n                        ),\n                        index = series.index, name=\"MA_Cross\"\n                )\n        return pd.concat([ma1, ma2, cross], axis=1)","metadata":{"execution":{"iopub.status.busy":"2022-07-05T03:54:20.729863Z","iopub.execute_input":"2022-07-05T03:54:20.730728Z","iopub.status.idle":"2022-07-05T03:54:20.754296Z","shell.execute_reply.started":"2022-07-05T03:54:20.730686Z","shell.execute_reply":"2022-07-05T03:54:20.753516Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def holiday(d):\n    return pd.DataFrame({\n        \"before_holiday\":(d[\"Date\"] != d[\"Date\"].shift(-1) - datetime.timedelta(days=1)) | (d[\"weekday\"]==4),\n        \"after_holiday\":(d[\"Date\"] != d[\"Date\"].shift(1) + datetime.timedelta(days=1)) | (d[\"weekday\"]==0)\n    }, index=d.index)\ndef make_features(df):\n    df = df[[\n        \"Date\",\"SecuritiesCode\",\"Open\",\"Close\",\"AdjustmentFactor\",\n        \"Volume\"\n    ]].copy()\n    df[\"weekday\"] = df[\"Date\"].dt.weekday\n    df = df.join(df.groupby(\"SecuritiesCode\").apply(holiday))\n    df[\"Volume_ratio\"] = df[\"Volume\"]/df.groupby(\"SecuritiesCode\")[\"Volume\"].rolling(window=15, min_periods=1).mean().reset_index(\"SecuritiesCode\",drop=True)\n    df[\"Close_adj\"] = df.groupby(\"SecuritiesCode\").apply(lambda d:d[\"Close\"]/d[\"AdjustmentFactor\"].cumprod().shift().fillna(1)).reset_index(\"SecuritiesCode\",drop=True)\n    df[[\"MA1\", \"MA2\", \"MA_Cross\"]] = df.groupby(\"SecuritiesCode\").apply(lambda d: MAFeature()._create_feature(d.Close_adj))# .join(df[\"Target\"].shift(-1)).groupby(\"MA_Cross\").describe()\n    df[\"Diff\"] = (df[\"Close\"] - df[\"Open\"]) / df[[\"Close\",\"Open\"]].mean(axis=1)\n    df[\"Diff_MA1\"] = df[\"Close_adj\"] - df[\"MA1\"]\n    df[\"Diff_MA2\"] = df[\"Close_adj\"] - df[\"MA2\"]\n    for i in range(1, 3):\n        df[\"MA_Cross_lag_{:}\".format(i)] = df.groupby(\"SecuritiesCode\")[\"MA_Cross\"].shift(i)\n\n    df[\"DivMA\"] = df.groupby(\"SecuritiesCode\")[\"Close_adj\"].apply(DMA)\n    df[\"Div\"] = df.groupby(\"SecuritiesCode\")[\"Close_adj\"].apply(divergence)\n    df[\"Rsi\"] = df.groupby(\"SecuritiesCode\")[\"Close_adj\"].apply(rsi)\n    df = df.join(df.groupby(\"SecuritiesCode\")[\"Close_adj\"].apply(stochastic))\n    \n    ##################（Add features）#######################\n    \n    ##################（Add features）#######################\n    return df","metadata":{"execution":{"iopub.status.busy":"2022-07-05T03:54:21.679172Z","iopub.execute_input":"2022-07-05T03:54:21.679579Z","iopub.status.idle":"2022-07-05T03:54:21.696315Z","shell.execute_reply.started":"2022-07-05T03:54:21.679547Z","shell.execute_reply":"2022-07-05T03:54:21.695259Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"columns = [\n    \"Diff\", \"Close_adj\",\"Volume_ratio\",\n    \"before_holiday\", \"after_holiday\",\n    \"Diff_MA1\", \"Diff_MA2\",\"MA_Cross\",\n    'MA_Cross_lag_1', 'MA_Cross_lag_2',\n    \"DivMA\", \"Div\", \"Rsi\", \"%K\", \"FAST-%D\",\"SLOW-%D\",\n]","metadata":{"execution":{"iopub.status.busy":"2022-07-05T04:12:19.809689Z","iopub.execute_input":"2022-07-05T04:12:19.810429Z","iopub.status.idle":"2022-07-05T04:12:19.837137Z","shell.execute_reply.started":"2022-07-05T04:12:19.810336Z","shell.execute_reply":"2022-07-05T04:12:19.836352Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# （Build model）","metadata":{}},{"cell_type":"code","source":"%%time\ndf = pd.read_csv(\"../input/jpx-tokyo-stock-exchange-prediction/supplemental_files/stock_prices.csv\", parse_dates=[\"Date\"])\ndf = make_features(df).join(df.Target)","metadata":{"execution":{"iopub.status.busy":"2022-07-05T03:54:25.847773Z","iopub.execute_input":"2022-07-05T03:54:25.848523Z","iopub.status.idle":"2022-07-05T03:56:49.207648Z","shell.execute_reply.started":"2022-07-05T03:54:25.848478Z","shell.execute_reply":"2022-07-05T03:56:49.206492Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_model(X, y):\n#     fast\n    model=LGBMRegressor(boosting_type=\"dart\",\n                        num_leaves=31,max_depth=12,\n                        learning_rate=0.2, n_estimators=100,\n                        random_state=0)\n#     model=LGBMRegressor(boosting_type=\"dart\",\n#                     num_leaves=31,max_depth=12,\n#                     learning_rate=0.02, n_estimators=1000,\n#                     random_state=0)\n    model.fit(X,y)\n    # model.score(X,y)\n    return model","metadata":{"execution":{"iopub.status.busy":"2022-07-05T03:56:49.209657Z","iopub.execute_input":"2022-07-05T03:56:49.210188Z","iopub.status.idle":"2022-07-05T03:56:49.217630Z","shell.execute_reply.started":"2022-07-05T03:56:49.210142Z","shell.execute_reply":"2022-07-05T03:56:49.216403Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# %%time\n# def train_model_val(X, y, validation=True):\n#     model=LGBMRegressor(boosting_type=\"dart\",\n#                         num_leaves=31,max_depth=12,\n#                         learning_rate=0.1, n_estimators=1000,\n#                         random_state=42)\n\n#     if validation:\n#         valid_ratio = 0.2\n#         n = int(len(X) * valid_ratio)\n#         model.fit(X.iloc[:-n].values, y.iloc[:-n].values)\n#         score = model.score(X.iloc[n:],y.iloc[n:])\n#     else:\n#         score = np.nan\n    \n#     model.fit(X.values,y.values)\n#     return model, score\n\n# columns2 = columns + list(transformed.columns)\n# models2 = {}\n# scores = {}\n# for code, d in df.groupby(\"SecuritiesCode\"):\n#     _d = d[~d.Target.isnull()].set_index(\"Date\")\n#     X = _d[columns].join(transformed)[columns2]\n#     y = _d.Target\n#     model, score = train_model2(X, y)\n#     models2[code] = model\n#     scores[code] = score\n#     print(\"Validation\",code, score)","metadata":{"execution":{"iopub.status.busy":"2022-07-05T03:56:49.219438Z","iopub.execute_input":"2022-07-05T03:56:49.220255Z","iopub.status.idle":"2022-07-05T03:56:49.229525Z","shell.execute_reply.started":"2022-07-05T03:56:49.220006Z","shell.execute_reply":"2022-07-05T03:56:49.228345Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nmodels = {}\nnum = 0\nfor code, d in df.groupby(\"SecuritiesCode\"):\n    d = d[~d.Target.isnull()]\n    X = d[columns]\n    y = d.Target\n    model = train_model(X, y)\n    models[code] = model","metadata":{"execution":{"iopub.status.busy":"2022-07-05T03:56:49.231455Z","iopub.execute_input":"2022-07-05T03:56:49.231884Z","iopub.status.idle":"2022-07-05T03:57:57.560695Z","shell.execute_reply.started":"2022-07-05T03:56:49.231855Z","shell.execute_reply":"2022-07-05T03:57:57.559933Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# (evaluation)","metadata":{}},{"cell_type":"code","source":"import warnings, gc\nimport numpy as np \nimport pandas as pd\nimport matplotlib.colors\nimport seaborn as sns\nimport plotly.express as px\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\nfrom plotly.offline import init_notebook_mode\n# from datetime import datetime, timedelta\nfrom sklearn.model_selection import TimeSeriesSplit\nfrom sklearn.metrics import mean_squared_error,mean_absolute_error\nfrom lightgbm import LGBMRegressor\nfrom decimal import ROUND_HALF_UP, Decimal\nwarnings.filterwarnings(\"ignore\")\nimport plotly.figure_factory as ff","metadata":{"execution":{"iopub.status.busy":"2022-07-05T03:57:57.564436Z","iopub.execute_input":"2022-07-05T03:57:57.566889Z","iopub.status.idle":"2022-07-05T03:57:57.576219Z","shell.execute_reply.started":"2022-07-05T03:57:57.566846Z","shell.execute_reply":"2022-07-05T03:57:57.575086Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def calc_spread_return_sharpe(df: pd.DataFrame, portfolio_size: int = 200, toprank_weight_ratio: float = 2) -> float:\n    \"\"\"\n    Args:\n        df (pd.DataFrame): predicted results\n        portfolio_size (int): # of equities to buy/sell\n        toprank_weight_ratio (float): the relative weight of the most highly ranked stock compared to the least.\n    Returns:\n        (float): sharpe ratio\n    \"\"\"\n    def _calc_spread_return_per_day(df, portfolio_size, toprank_weight_ratio):\n        \"\"\"\n        Args:\n            df (pd.DataFrame): predicted results\n            portfolio_size (int): # of equities to buy/sell\n            toprank_weight_ratio (float): the relative weight of the most highly ranked stock compared to the least.\n        Returns:\n            (float): spread return\n        \"\"\"\n        assert df['Rank'].min() == 0\n        assert df['Rank'].max() == len(df['Rank']) - 1\n#         weights = np.linspace(start=toprank_weight_ratio, stop=1, num=portfolio_size)\n        df_len = len(df)\n        if df_len>=portfolio_size:\n            weights = np.linspace(start=toprank_weight_ratio, stop=1, num=portfolio_size)\n            purchase = (df.sort_values(by='Rank')['Target'][:portfolio_size] * weights).sum() / weights.mean()\n        else:\n            weights = np.linspace(start=toprank_weight_ratio, stop=1, num=df_len)\n            purchase = (df.sort_values(by='Rank')['Target'][:df_len] * weights).sum() / weights.mean()\n        short = (df.sort_values(by='Rank', ascending=False)['Target'][:portfolio_size] * weights).sum() / weights.mean()\n        return purchase - short\n\n    buf = df.groupby('Date').apply(_calc_spread_return_per_day, portfolio_size, toprank_weight_ratio)\n    sharpe_ratio = buf.mean() / buf.std()\n    return sharpe_ratio","metadata":{"execution":{"iopub.status.busy":"2022-07-05T03:57:57.578613Z","iopub.execute_input":"2022-07-05T03:57:57.579113Z","iopub.status.idle":"2022-07-05T03:57:57.594401Z","shell.execute_reply.started":"2022-07-05T03:57:57.579066Z","shell.execute_reply":"2022-07-05T03:57:57.593214Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nts_fold = TimeSeriesSplit(n_splits=5, gap=0)\ndf_input = df.copy().sort_values(['Date','SecuritiesCode'])\n# prices=price_features.dropna().sort_values(['Date','SecuritiesCode'])\ny=df_input['Target'].to_numpy()\nX=df_input.drop(['Target'],axis=1)\n\nfeat_importance=pd.DataFrame()\nsharpe_ratio=[]\nresult = {}\n    \nfor fold, (train_idx, val_idx) in enumerate(ts_fold.split(X, y)):\n    \n    print(\"\\n========================== Fold {} ==========================\".format(fold+1))\n    df_train = df_input.iloc[train_idx,:]\n    df_valid = df_input.iloc[val_idx,:]\n    X_train, y_train = X.iloc[train_idx,:], y[train_idx]\n    X_valid, y_val = X.iloc[val_idx,:], y[val_idx]\n    \n    print(\"Train Date range: {} to {}\".format(X_train.Date.min(),X_train.Date.max()))\n    print(\"Valid Date range: {} to {}\".format(X_valid.Date.min(),X_valid.Date.max()))\n    \n#     X_train.drop(['Date','SecuritiesCode'], axis=1, inplace=True)\n#     X_train.drop(['Date'], axis=1, inplace=True)\n#     X_val=X_valid[X_valid.columns[~X_valid.columns.isin(['Date','SecuritiesCode'])]]\n#     val_dates=X_valid.Date.unique()[1:-1]\n#     print(\"\\nTrain Shape: {} {}, Valid Shape: {} {}\".format(X_train.shape, y_train.shape, X_val.shape, y_val.shape))\n    \n#     params = {'n_estimators': 1000,\n#               'num_leaves' : 31,\n#               'max_depth' : 12,\n#               'learning_rate': 0.02,\n#               'colsample_bytree': 0.9,\n#               'subsample': 0.8,\n#               'reg_alpha': 0.4,\n#               'metric': 'mae',\n#               'random_state': 0,\n#               'boosting_type': \"dart\"\n#               }\n\n#     gbm = LGBMRegressor(**params).fit(X_train, y_train, \n#                                       eval_set=[(X_train, y_train), (X_val, y_val)],\n#                                       verbose=300, \n#                                       eval_metric=['mae','mse'])\n\n    models = {}\n    for code, d in df_train.groupby(\"SecuritiesCode\"):\n        X_tmp = d[columns]\n        y_tmp = d.Target\n        model = train_model(X_tmp[~y_tmp.isnull()], y_tmp[~y_tmp.isnull()])\n        models[code] = model\n        \n#     gbm = train_model(X_train, y_train)\n#     y_pred = gbm.predict(X_val)\n#     rmse = np.sqrt(mean_squared_error(y_val, y_pred))\n#     mae = mean_absolute_error(y_val, y_pred)\n#     feat_importance[\"Importance_Fold\"+str(fold)]=gbm.feature_importances_\n#     feat_importance.set_index(X_train.columns, inplace=True)\n    \n    rank=[]\n    df_valid_tmp = df_valid.copy()\n#     X_val_df=X_valid[X_valid.Date.isin(val_dates)]\n    for i, d in df_valid_tmp.groupby(\"SecuritiesCode\"):\n        df_valid_tmp.loc[d.index, \"pred\"]=models[i].predict(d[columns])\n    for date, d in df_valid_tmp.groupby(\"Date\"):\n        df_valid_tmp.loc[d.index, \"Rank\"]= (d.pred.rank(method=\"first\", ascending=False)-1).astype(int)\n#     val_df_tmp = X_val_df.merge(y_val)\n    sharpe=calc_spread_return_sharpe(df_valid_tmp)\n    result[fold] =  df_valid_tmp\n    \n#     for i in X_val_df.Date.unique():\n#         tmp_result_list = []\n#         code_list = []\n#         for i_code in X_val_df[(X_val_df.Date == i)].SecuritiesCode.unique():\n#             temp_df = X_val_df[(X_val_df.Date == i)&(X_val_df.SecuritiesCode == i_code)].drop(['Date','SecuritiesCode'],axis=1)\n#             tmp_result = models[code].predict(temp_df[columns])\n#             tmp_result_list.append(tmp_result)\n#             code_list.append(code_list)\n#         temp_df = pd.DataFrame({\"pred\":tmp_result_list, })\n#         temp_df[\"Rank\"] = (temp_df[\"pred\"].rank(method=\"first\", ascending=False)-1).astype(int)\n#         rank.append(temp_df[\"Rank\"].values)\n\n#     stock_rank=pd.Series([x for y in rank for x in y], name=\"Rank\")\n#     df_tmp=pd.concat([X_val_df.reset_index(drop=True),stock_rank,\n#                   prices[prices.Date.isin(val_dates)]['Target'].reset_index(drop=True)], axis=1)\n#     sharpe=calc_spread_return_sharpe(df_tmp)\n    sharpe_ratio.append(sharpe)\n    print(\"Valid Sharpe: {}\".format(sharpe))\n    \n    \n#     del X_train, y_train,  X_val, y_val\n#     gc.collect()\n    \nprint(\"\\nAverage cross-validation Sharpe Ratio: {:.4f}, standard deviation = {:.2f}.\".format(np.mean(sharpe_ratio),np.std(sharpe_ratio)))","metadata":{"execution":{"iopub.status.busy":"2022-07-05T03:57:57.595656Z","iopub.execute_input":"2022-07-05T03:57:57.596103Z","iopub.status.idle":"2022-07-05T04:02:07.711968Z","shell.execute_reply.started":"2022-07-05T03:57:57.596073Z","shell.execute_reply":"2022-07-05T04:02:07.710971Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# （Predict）","metadata":{}},{"cell_type":"code","source":"import jpx_tokyo_market_prediction\nenv = jpx_tokyo_market_prediction.make_env()\niter_test = env.iter_test()    ","metadata":{"execution":{"iopub.status.busy":"2022-07-05T04:27:56.869971Z","iopub.execute_input":"2022-07-05T04:27:56.870400Z","iopub.status.idle":"2022-07-05T04:27:56.895018Z","shell.execute_reply.started":"2022-07-05T04:27:56.870363Z","shell.execute_reply":"2022-07-05T04:27:56.894257Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = df.copy()\nfor (prices, options, financials, trades, secondary_prices, sample_prediction) in iter_test:\n    display(prices)\n    prices[\"Date\"] = pd.to_datetime(prices[\"Date\"])\n#     data = prices.drop_duplicates([\"SecuritiesCode\", \"Date\"], keep=\"last\").sort_values([\"SecuritiesCode\", \"Date\"]).reset_index(drop=True)\n    data = data.append(prices).drop_duplicates([\"SecuritiesCode\", \"Date\"], keep=\"last\").sort_values([\"SecuritiesCode\", \"Date\"]).reset_index(drop=True)\n    data = make_features(data)\n    \n    d = sample_prediction[[\"Date\",\"SecuritiesCode\"]].reset_index()\n    d[\"Date\"] = pd.to_datetime(d[\"Date\"])\n    d = d.merge(data, on=[\"Date\",\"SecuritiesCode\"])\n    for code, _d in d.groupby(\"SecuritiesCode\"):\n        d.loc[_d.index, \"Pred\"] = models[code].predict(_d[columns])#予測\n    d = d.sort_values(by=\"Pred\", ascending=False).set_index(\"index\")\n    d[\"Rank\"] = np.arange(0,2000)\n    \n    d = d.sort_index()\n    sample_prediction[\"Rank\"] = d[\"Rank\"]\n    \n    submission = sample_prediction[[\"Date\",\"SecuritiesCode\",\"Rank\"]]\n    env.predict(submission)","metadata":{"execution":{"iopub.status.busy":"2022-07-05T04:06:12.066856Z","iopub.execute_input":"2022-07-05T04:06:12.067271Z","iopub.status.idle":"2022-07-05T04:06:12.099036Z","shell.execute_reply.started":"2022-07-05T04:06:12.067238Z","shell.execute_reply":"2022-07-05T04:06:12.097933Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}